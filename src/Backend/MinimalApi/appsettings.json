{
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft.AspNetCore": "Warning",
      "Microsoft": "Warning"
    }
  },

  "AzureStorageContainer": "input",
  "InputAzureStorageContainer": "input",
  "OutputAzureStorageContainer": "output",
  "AzureSearchServiceEndpoint": "https://hack-togather-as.search.windows.net",

  "AzureStorageAccountConnectionString": "DefaultEndpointsProtocol=https;AccountName=hacktogatherstorage;AccountKey=ho9sGOqK1r/365dfV/i2GsPiMcJwK/E6d30q0XkSRYUYMIz4D73RRJ4/drDiMc3lZk+i5CCUAJKN+AStDaN5fQ==;EndpointSuffix=core.windows.net",
  "BlobStorage": "DefaultEndpointsProtocol=https;AccountName=hacktogatherstorage;AccountKey=ho9sGOqK1r/365dfV/i2GsPiMcJwK/E6d30q0XkSRYUYMIz4D73RRJ4/drDiMc3lZk+i5CCUAJKN+AStDaN5fQ==;EndpointSuffix=core.windows.net",

  "AzureSearchIndex": "test",
  "AzureOpenAiServiceEndpoint": "https://hack-togather-oai.openai.azure.com/",
  "AzureDocumentIntelligenceEndpoint": "https://hack-togather-di.cognitiveservices.azure.com/",

  "AzureStorageAccountEndpoint": "https://hacktogatherstorage.blob.core.windows.net/input",

  "AzureStorageAccountEndpointKey": "ho9sGOqK1r/365dfV/i2GsPiMcJwK/E6d30q0XkSRYUYMIz4D73RRJ4/drDiMc3lZk+i5CCUAJKN+AStDaN5fQ==",
  "AzureSearchServiceEndpointKey": "t6Nix6RczFKu0h14WVBjNOci1KGehRMtDCpaJrVswGAzSeDDjSTd",
  "AzureOpenAiServiceEndpointKey": "c7b1415df21e4e5aa1daf262f7f39eaf",
  "AzureDocumentIntelligenceEndpointKey": "2f0de0a48d9241649941c4ca5a10aa33",
  "AZURE_OPENAI_CHATGPT_DEPLOYMENT": "hack-togather-gpt-4-32",
  "AzureOpenAiChatGptDeployment": "hack-togather-gpt-4-32",
  "AzureOpenAiEmbeddingDeployment": "hack-togather-ada",
  "AZURE_OPENAI_RESOURCE_GROUP ": "hack-togather",

  "AZURE_OPENAI_EMBEDDING_DEPLOYMENT": "hack-togather-ada",

  "AppSettings": {
    "BACKEND_URI": "https://hack-togather-api.azurewebsites.net/"
    //"BACKEND_URI": "https://localhost:7181/"
  },

  "CosmosDB": {
    "EndpointUrl": "https://hacktogather.documents.azure.com:443/",
    "Name": "Auth",
    "ContainerName": "User",
    "CheckCosmosClientSetup": "true"
  },

  "AzureAd": {
    "Instance": "https://sts.windows.net/",
    "Domain": "docassistant.info",
    "TenantId": "9dfb337e-c650-4a06-84d2-ca94548713e8",
    "ClientId": "e336c21e-cff8-46d8-b1b9-e6fcc6cfa851",
    "ClientSecret": "Aav8Q~~tsebR~k6n_wSlztT6WtHqka0n4AHpDddi",
    "GraphScope": "https://graph.microsoft.com/.default"
  },

  "SwaggerAiAssistant": {
    "SystemPromptSwaggerPath": "/Prompts/SystemPrompts/system-prompt-swagger.txt"
  },

  "KernelMemory": {
    "Services": {
      "AzureAISearch": {
        // "ApiKey" or "AzureIdentity". For other options see <AzureAISearchConfig>.
        // AzureIdentity: use automatic AAD authentication mechanism. You can test locally
        //   using the env vars AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET.
        "Auth": "ApiKey",
        "Endpoint": "https://hack-togather-as.search.windows.net",
        "APIKey": "etDFECFpMYyn0mnnW1VmY8N2aHEXJhy8MLMmOvdYZoAzSeAS9WOJ"
      },
      "AzureBlobs": {
        // "ConnectionString" or "AzureIdentity". For other options see <AzureBlobConfig>.
        // AzureIdentity: use automatic AAD authentication mechanism. You can test locally
        //   using the env vars AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET.
        "Auth": "ConnectionString",
        // Azure Storage account name, required when using AzureIdentity auth
        // Note: you can use an env var 'KernelMemory__Services__AzureBlobs__Account' to set this
        "Account": "hacktogatherstorage",
        // Container where to create directories and upload files
        "Container": "smemory",
        // Required when Auth == ConnectionString
        // Note: you can use an env var 'KernelMemory__Services__AzureBlobs__ConnectionString' to set this
        "ConnectionString": "DefaultEndpointsProtocol=https;AccountName=hacktogatherstorage;AccountKey=Q/nlQ5lcFgumEAK5RbzpYfTSkVF7mc9CpjLVTHDx270/99lxtEp5KzypZXPwh6XH9GiG9fgbOgZ2+AStXFPC5A==;EndpointSuffix=core.windows.net",
        // Setting used only for country clouds
        "EndpointSuffix": "core.windows.net"
      },
      "AzureOpenAIText": {
        // "ApiKey" or "AzureIdentity"
        // AzureIdentity: use automatic AAD authentication mechanism. You can test locally
        //   using the env vars AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET.
        "Auth": "ApiKey",
        "Endpoint": "https://hack-togather-oai.openai.azure.com/",
        "APIKey": "85e52c16d7a54ee19166d75a863ebd4d",
        "Deployment": "gpt-35",
        // The max number of tokens supported by model deployed
        // See https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models
        "MaxTokenTotal": 16384,
        // "ChatCompletion" or "TextCompletion"
        "APIType": "ChatCompletion",
        "MaxRetries": 10
      },
      "AzureOpenAIEmbedding": {
        // "ApiKey" or "AzureIdentity"
        // AzureIdentity: use automatic AAD authentication mechanism. You can test locally
        //   using the env vars AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET.
        "Auth": "ApiKey",
        "Endpoint": "https://hack-togather-oai.openai.azure.com/",
        "APIKey": "85e52c16d7a54ee19166d75a863ebd4d",
        "Deployment": "hack-togather-ada",
        // The max number of tokens supported by model deployed
        // See https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models
        "MaxTokenTotal": 8191
      }
    },
    "Retrieval": {
      "SearchClient": {
        // Maximum number of tokens accepted by the LLM used to generate answers.
        // The number includes the tokens used for the answer, e.g. when using
        // GPT4-32k, set this number to 32768.
        // If the value is not set or less than one, SearchClient will use the
        // max amount of tokens supported by the model in use.
        "MaxAskPromptSize": -1,
        // Maximum number of relevant sources to consider when generating an answer.
        // The value is also used as the max number of results returned by SearchAsync
        // when passing a limit less or equal to zero.
        "MaxMatchesCount": 100,
        // How many tokens to reserve for the answer generated by the LLM.
        // E.g. if the LLM supports max 4000 tokens, and AnswerTokens is 300, then
        // the prompt sent to LLM will contain max 3700 tokens, composed by
        // prompt + question + grounding information retrieved from memory.
        "AnswerTokens": 300,
        // Text to return when the LLM cannot produce an answer.
        "EmptyAnswer": "INFO NOT FOUND"
      }
    }
  }
}